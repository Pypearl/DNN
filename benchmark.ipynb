{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**!** This notebook has to be run after the following notebooks:\n",
    "- [dataset.ipynb](dataset.ipynb)\n",
    "- [scoring.ipynb](scoring.ipynb)\n",
    "- [model.ipynb](model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import dataset\n",
    "import scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| using constant padding\n",
      "| using scales: [0.8333333333333334, 1.0, 1.2]\n",
      "| using ordinary correlation\n",
      "load pretrained model from models/SiamSE/checkpoint_vot.pth\n",
      "remove prefix \"module.\"\n",
      "missing keys:set()\n",
      "unused checkpoint keys:set()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/33652/Documents/ING 2 Prog/DeepNN/venv_dnn/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/33652/Documents/ING 2 Prog/DeepNN/venv_dnn/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "models = model.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while loading dataset David gt and image files have different length\n",
      "Error while loading dataset Football1 gt and image files have different length\n",
      "Error while loading dataset Jogging1 gt and image files have different length\n",
      "Error while loading dataset Jogging2 gt and image files have different length\n",
      "Error while loading dataset Subway gt and image files have different length\n"
     ]
    }
   ],
   "source": [
    "datasets = dataset.load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['SEsiamFC', 'AAA']), dict_keys(['mytc128', 'myvot2021']))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.keys(), datasets.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_video(tracker, video, verbose=False):\n",
    "    start_frame, toc = 0, 0\n",
    "\n",
    "    pred = []\n",
    "    image_files, gt = video['image_files'], video['gt']\n",
    "\n",
    "    for f, image_file in enumerate(image_files):\n",
    "        tic = cv2.getTickCount()\n",
    "\n",
    "        if f == start_frame:  # init\n",
    "            tracker.initialize(image_file, np.array(gt[f]))\n",
    "            pred.append(gt[f])\n",
    "\n",
    "        elif f > start_frame:  # tracking\n",
    "            pred_bbox = tracker.track(image_file)\n",
    "            print(\"{} gt: {} pred: {}\".format(f, gt[f], pred_bbox))\n",
    "            b_overlap = scoring.get_precision(gt[f], pred_bbox)\n",
    "            if b_overlap > 0:\n",
    "                pred.append(pred_bbox)\n",
    "            else:\n",
    "                pred.append(2)\n",
    "                start_frame = f + 5\n",
    "        else:\n",
    "            pred.append(0)\n",
    "\n",
    "        toc += cv2.getTickCount() - tic\n",
    "  \n",
    "    toc /= cv2.getTickFrequency()\n",
    "\n",
    "    precisions = [scoring.get_precision(gt[i], pred[i]) for i in range(len(gt))]\n",
    "    precisions = np.array(precisions)\n",
    "    mprec = np.mean(precisions)\n",
    "\n",
    "    success = [scoring.is_success(gt[i], pred[i]) for i in range(len(gt))]\n",
    "    success = np.array(success)\n",
    "    msucc = np.mean(success)\n",
    "\n",
    "    fps = f / toc\n",
    "\n",
    "    if verbose:\n",
    "        print('Video: {:12s} Time: {:2.1f}s Speed: {:3.1f}fps mSuccess: {:3.1f} mPrecision {:3.1f}'.format(video['name'], toc, f / toc, msucc, mprec))\n",
    "    return mprec, msucc, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = models['SEsiamFC']\n",
    "t2 = models['AAA']\n",
    "d1 = datasets['mytc128']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = d1['Cup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video: Cup          Time: 34.9s Speed: 8.7fps mSuccess: 1.0 mPrecision 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8127891293539966, 1.0, 8.653954689228593)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_video(t1, v1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 gt: [124, 92, 46, 59] pred: [0. 0. 0. 0.]\n",
      "7 gt: [123, 93, 46, 57] pred: [0. 0. 0. 0.]\n",
      "13 gt: [120, 97, 46, 58] pred: [0. 0. 0. 0.]\n",
      "19 gt: [116, 98, 46, 57] pred: [0. 0. 0. 0.]\n",
      "25 gt: [122, 94, 46, 56] pred: [0. 0. 0. 0.]\n",
      "31 gt: [128, 88, 44, 56] pred: [0. 0. 0. 0.]\n",
      "37 gt: [120, 82, 44, 54] pred: [0. 0. 0. 0.]\n",
      "43 gt: [118, 92, 42, 54] pred: [0. 0. 0. 0.]\n",
      "49 gt: [121, 97, 41, 53] pred: [0. 0. 0. 0.]\n",
      "55 gt: [124, 95, 43, 53] pred: [0. 0. 0. 0.]\n",
      "61 gt: [122, 97, 43, 52] pred: [0. 0. 0. 0.]\n",
      "67 gt: [124, 108, 40, 49] pred: [0. 0. 0. 0.]\n",
      "73 gt: [126, 99, 37, 46] pred: [0. 0. 0. 0.]\n",
      "79 gt: [125, 84, 38, 46] pred: [0. 0. 0. 0.]\n",
      "85 gt: [122, 90, 38, 45] pred: [0. 0. 0. 0.]\n",
      "91 gt: [113, 98, 38, 46] pred: [0. 0. 0. 0.]\n",
      "97 gt: [104, 105, 37, 47] pred: [0. 0. 0. 0.]\n",
      "103 gt: [107, 107, 40, 46] pred: [0. 0. 0. 0.]\n",
      "109 gt: [124, 105, 42, 49] pred: [0. 0. 0. 0.]\n",
      "115 gt: [136, 103, 41, 49] pred: [0. 0. 0. 0.]\n",
      "121 gt: [129, 106, 42, 49] pred: [0. 0. 0. 0.]\n",
      "127 gt: [117, 95, 42, 50] pred: [0. 0. 0. 0.]\n",
      "133 gt: [108, 98, 41, 50] pred: [0. 0. 0. 0.]\n",
      "139 gt: [111, 108, 41, 50] pred: [0. 0. 0. 0.]\n",
      "145 gt: [111, 105, 42, 50] pred: [0. 0. 0. 0.]\n",
      "151 gt: [96, 100, 42, 49] pred: [0. 0. 0. 0.]\n",
      "157 gt: [87, 101, 41, 50] pred: [0. 0. 0. 0.]\n",
      "163 gt: [89, 105, 40, 50] pred: [0. 0. 0. 0.]\n",
      "169 gt: [86, 111, 40, 48] pred: [0. 0. 0. 0.]\n",
      "175 gt: [81, 106, 38, 47] pred: [0. 0. 0. 0.]\n",
      "181 gt: [71, 103, 38, 48] pred: [0. 0. 0. 0.]\n",
      "187 gt: [63, 104, 38, 46] pred: [0. 0. 0. 0.]\n",
      "193 gt: [67, 108, 37, 46] pred: [0. 0. 0. 0.]\n",
      "199 gt: [66, 107, 38, 45] pred: [0. 0. 0. 0.]\n",
      "205 gt: [62, 100, 38, 47] pred: [0. 0. 0. 0.]\n",
      "211 gt: [70, 96, 39, 47] pred: [0. 0. 0. 0.]\n",
      "217 gt: [76, 92, 38, 48] pred: [0. 0. 0. 0.]\n",
      "223 gt: [86, 89, 38, 49] pred: [0. 0. 0. 0.]\n",
      "229 gt: [99, 98, 39, 52] pred: [0. 0. 0. 0.]\n",
      "235 gt: [113, 113, 41, 53] pred: [0. 0. 0. 0.]\n",
      "241 gt: [110, 105, 43, 56] pred: [0. 0. 0. 0.]\n",
      "247 gt: [87, 95, 43, 58] pred: [0. 0. 0. 0.]\n",
      "253 gt: [74, 90, 42, 59] pred: [0. 0. 0. 0.]\n",
      "259 gt: [94, 99, 42, 59] pred: [0. 0. 0. 0.]\n",
      "265 gt: [106, 112, 41, 56] pred: [0. 0. 0. 0.]\n",
      "271 gt: [119, 98, 40, 54] pred: [0. 0. 0. 0.]\n",
      "277 gt: [113, 80, 42, 53] pred: [0. 0. 0. 0.]\n",
      "283 gt: [95, 62, 43, 54] pred: [0. 0. 0. 0.]\n",
      "289 gt: [84, 63, 46, 56] pred: [0. 0. 0. 0.]\n",
      "295 gt: [77, 75, 47, 57] pred: [0. 0. 0. 0.]\n",
      "301 gt: [82, 86, 49, 60] pred: [0. 0. 0. 0.]\n",
      "Video: Cup          Time: 208.6s Speed: 1.4fps mSuccess: 0.2 mPrecision 0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.16831683168316833, 0.16831683168316833, 1.4476557371959673)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_video(t2, v1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_dnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96d6dd9d829a4a8dd1edda94add76f4a08841e645b8132fdf668d21ba72dd652"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
