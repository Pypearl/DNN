{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**!** This notebook has to be run after the following notebooks:\n",
    "\n",
    "-   [dataset.ipynb](dataset.ipynb)\n",
    "-   [scoring.ipynb](scoring.ipynb)\n",
    "-   [model.ipynb](model.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import dataset\n",
    "import scoring\n",
    "\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| using constant padding\n",
      "| using scales: [0.8333333333333334, 1.0, 1.2]\n",
      "| using ordinary correlation\n",
      "load pretrained model from models/SiamSE/checkpoint_vot.pth\n",
      "remove prefix \"module.\"\n",
      "missing keys:set()\n",
      "unused checkpoint keys:set()\n",
      "test config:  {'MODEL': {'HEAD_TYPE': 'CORNER', 'HIDDEN_DIM': 384, 'NUM_OBJECT_QUERIES': 1, 'POSITION_EMBEDDING': 'sine', 'PREDICT_MASK': False, 'BACKBONE': {'PRETRAINED': True, 'PRETRAINED_PATH': '/YOUR/PRETRAINED/CVT/DIR/CvT-21-384x384-IN-22k.pth', 'INIT': 'trunc_norm', 'NUM_STAGES': 3, 'PATCH_SIZE': [7, 3, 3], 'PATCH_STRIDE': [4, 2, 2], 'PATCH_PADDING': [2, 1, 1], 'DIM_EMBED': [64, 192, 384], 'NUM_HEADS': [1, 3, 6], 'DEPTH': [1, 4, 16], 'MLP_RATIO': [4.0, 4.0, 4.0], 'ATTN_DROP_RATE': [0.0, 0.0, 0.0], 'DROP_RATE': [0.0, 0.0, 0.0], 'DROP_PATH_RATE': [0.0, 0.0, 0.1], 'QKV_BIAS': [True, True, True], 'CLS_TOKEN': [False, False, False], 'POS_EMBED': [False, False, False], 'QKV_PROJ_METHOD': ['dw_bn', 'dw_bn', 'dw_bn'], 'KERNEL_QKV': [3, 3, 3], 'PADDING_KV': [1, 1, 1], 'STRIDE_KV': [2, 2, 2], 'PADDING_Q': [1, 1, 1], 'STRIDE_Q': [1, 1, 1], 'FREEZE_BN': True}}, 'TRAIN': {'LR': 0.0001, 'WEIGHT_DECAY': 0.0001, 'EPOCH': 500, 'LR_DROP_EPOCH': 400, 'BATCH_SIZE': 8, 'NUM_WORKER': 8, 'OPTIMIZER': 'ADAMW', 'BACKBONE_MULTIPLIER': 0.1, 'GIOU_WEIGHT': 2.0, 'L1_WEIGHT': 5.0, 'DEEP_SUPERVISION': False, 'FREEZE_STAGE0': False, 'PRINT_INTERVAL': 50, 'VAL_EPOCH_INTERVAL': 5, 'GRAD_CLIP_NORM': 0.1, 'SCHEDULER': {'TYPE': 'step', 'DECAY_RATE': 0.1}}, 'DATA': {'MEAN': [0.485, 0.456, 0.406], 'STD': [0.229, 0.224, 0.225], 'MAX_SAMPLE_INTERVAL': 200, 'TRAIN': {'DATASETS_NAME': ['GOT10K_vottrain', 'LASOT', 'COCO17', 'TRACKINGNET'], 'DATASETS_RATIO': [1, 1, 1, 1], 'SAMPLE_PER_EPOCH': 60000}, 'VAL': {'DATASETS_NAME': ['GOT10K_votval'], 'DATASETS_RATIO': [1], 'SAMPLE_PER_EPOCH': 10000}, 'SEARCH': {'SIZE': 320, 'FACTOR': 5.0, 'CENTER_JITTER': 4.5, 'SCALE_JITTER': 0.5}, 'TEMPLATE': {'SIZE': 128, 'FACTOR': 2.0, 'NUMBER': 2, 'CENTER_JITTER': 0, 'SCALE_JITTER': 0}}, 'TEST': {'TEMPLATE_FACTOR': 2.0, 'TEMPLATE_SIZE': 128, 'SEARCH_FACTOR': 5.0, 'SEARCH_SIZE': 320, 'EPOCH': 500, 'UPDATE_INTERVALS': {'LASOT': [200], 'GOT10K_TEST': [200], 'TRACKINGNET': [25], 'VOT20': [10], 'VOT20LT': [200]}}}\n",
      "Warning: Pretrained CVT weights are not loaded\n",
      "head channel: 384\n",
      "Update interval is:  200\n"
     ]
    }
   ],
   "source": [
    "models: Dict[str, model.Tracker] = model.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while loading dataset /mnt/d/Documents/DNN_project/projet/data/mytc128/David gt and image files have different length\n",
      "Error while loading dataset /mnt/d/Documents/DNN_project/projet/data/mytc128/Football1 gt and image files have different length\n",
      "Error while loading dataset /mnt/d/Documents/DNN_project/projet/data/mytc128/Jogging1 gt and image files have different length\n",
      "Error while loading dataset /mnt/d/Documents/DNN_project/projet/data/mytc128/Jogging2 gt and image files have different length\n",
      "Error while loading dataset /mnt/d/Documents/DNN_project/projet/data/mytc128/Subway gt and image files have different length\n"
     ]
    }
   ],
   "source": [
    "datasets: Dict = dataset.load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['Staple', 'SEsiamFC', 'PyECO', 'MixFormer', 'MIL', 'GOTURN']),\n",
       " dict_keys(['mytc128', 'myvot2021']))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.keys(), datasets.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_video(out, image_file, gt, pred=None):\n",
    "    \"\"\"Write a frame to the video.\n",
    "\n",
    "    Args:\n",
    "        out (cv2.VideoWriter): Video writer.\n",
    "        image_file (str): Path to the image file.\n",
    "        gt (List[int]): Ground truth bounding box.\n",
    "        pred (List[int], optional): Predicted bounding box. Defaults to None.\n",
    "    \"\"\"\n",
    "    im = cv2.imread(image_file)\n",
    "    cv2.rectangle(\n",
    "        im,\n",
    "        (int(gt[0]), int(gt[1])),\n",
    "        (int(gt[0] + gt[2]), int(gt[1] + gt[3])),\n",
    "        (0, 255, 0),\n",
    "        2,\n",
    "    )\n",
    "    if pred is not None:\n",
    "        cv2.rectangle(\n",
    "            im,\n",
    "            (int(pred[0]), int(pred[1])),\n",
    "            (int(pred[0] + pred[2]), int(pred[1] + pred[3])),\n",
    "            (0, 0, 255),\n",
    "            2,\n",
    "        )\n",
    "    out.write(im)\n",
    "\n",
    "\n",
    "def track_video(tracker, video, verbose=0, save_video=None):\n",
    "    \"\"\"Track a whole video.\n",
    "\n",
    "    Args:\n",
    "        tracker (model.Tracker): Tracker.\n",
    "        video (Dict): Video.\n",
    "        verbose (int, optional): Verbosity level. Defaults to 0.\n",
    "        save_video (str, optional): Path to the video to save. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float]: Precision, Success, FPS.\n",
    "    \"\"\"\n",
    "    start_frame, toc = 0, 0\n",
    "\n",
    "    pred = []\n",
    "    image_files, gt = video[\"image_files\"], video[\"gt\"]\n",
    "\n",
    "    if save_video is not None:\n",
    "        sh = cv2.imread(image_files[0]).shape[:2]\n",
    "        frame_size = (sh[1], sh[0])\n",
    "        out = cv2.VideoWriter(\n",
    "            save_video, cv2.VideoWriter_fourcc(*\"DIVX\"), 20.0, frame_size\n",
    "        )\n",
    "    \n",
    "    lost = 0\n",
    "    for f, image_file in enumerate(image_files):\n",
    "        tic = cv2.getTickCount()\n",
    "\n",
    "        if f == start_frame:  # init\n",
    "            tracker.initialize(image_file, np.array(gt[f]))\n",
    "            pred.append(gt[f])\n",
    "\n",
    "            if save_video is not None:\n",
    "                write_video(out, image_file, gt[f])\n",
    "\n",
    "        elif f > start_frame:  # tracking\n",
    "            pred_bbox = tracker.track(image_file)\n",
    "            b_overlap = scoring.get_score(pred_bbox, gt[f])\n",
    "            if b_overlap > 0:\n",
    "                pred.append(pred_bbox)\n",
    "            else:\n",
    "                pred.append(2)\n",
    "                start_frame = f + 5\n",
    "                lost += 1\n",
    "\n",
    "            if verbose > 1:\n",
    "                print(f\"{f} gt: {gt[f]} pred: {pred_bbox} overlap: {b_overlap}\")\n",
    "\n",
    "            if save_video is not None:\n",
    "                write_video(out, image_file, gt[f], pred_bbox)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "            if save_video is not None:\n",
    "                write_video(out, image_file, gt[f])\n",
    "\n",
    "        toc += cv2.getTickCount() - tic\n",
    "\n",
    "    toc /= cv2.getTickFrequency()\n",
    "\n",
    "    precisions = [scoring.get_precision(gt[i], pred[i]) for i in range(len(gt))]\n",
    "    scores = [scoring.get_score(gt[i], pred[i]) for i in range(len(gt))]\n",
    "\n",
    "    fps = f / toc\n",
    "\n",
    "    if verbose > 0:\n",
    "        print(\n",
    "            f'Video: {video[\"name\"]:12s} Time: {toc:2.1f}s Speed: {fps:5.2f}fps Lost: {lost}'\n",
    "        )\n",
    "\n",
    "    if save_video is not None:\n",
    "        out.release()\n",
    "\n",
    "    return precisions, scores, fps, lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mytc128\"\n",
    "tracker = \"MixFormer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Airport_ce', 'Baby_ce', 'Badminton_ce1', 'Badminton_ce2', 'Ball_ce1', 'Ball_ce2', 'Ball_ce3', 'Ball_ce4', 'Basketball', 'Basketball_ce1', 'Basketball_ce2', 'Basketball_ce3', 'Bee_ce', 'Bicycle', 'Biker', 'Bikeshow_ce', 'Bike_ce1', 'Bike_ce2', 'Bird', 'Board', 'Boat_ce1', 'Boat_ce2', 'Bolt', 'Boy', 'Busstation_ce1', 'Busstation_ce2', 'Carchasing_ce1', 'Carchasing_ce3', 'Carchasing_ce4', 'CarDark', 'CarScale', 'Charger_ce', 'Coke', 'Couple', 'Crossing', 'Cup', 'Cup_ce', 'David3', 'Deer', 'Diving', 'Doll', 'Eagle_ce', 'Electricalbike_ce', 'FaceOcc1', 'Face_ce', 'Face_ce2', 'Fish_ce1', 'Fish_ce2', 'Girl', 'Girlmov', 'Guitar_ce1', 'Guitar_ce2', 'Gym', 'Hand', 'Hand_ce1', 'Hand_ce2', 'Hurdle_ce1', 'Hurdle_ce2', 'Iceskater', 'Ironman', 'Juice', 'Kite_ce1', 'Kite_ce2', 'Kite_ce3', 'Kobe_ce', 'Lemming', 'Liquor', 'Logo_ce', 'Matrix', 'Messi_ce', 'Michaeljackson_ce', 'Microphone_ce1', 'Microphone_ce2', 'Motorbike_ce', 'MotorRolling', 'MountainBike', 'Panda', 'Plane_ce2', 'Plate_ce1', 'Plate_ce2', 'Pool_ce1', 'Pool_ce2', 'Pool_ce3', 'Railwaystation_ce', 'Ring_ce', 'Sailor_ce', 'Shaking', 'Singer1', 'Singer2', 'Singer_ce1', 'Singer_ce2', 'Skating1', 'Skating2', 'Skating_ce1', 'Skating_ce2', 'Skiing', 'Skiing_ce', 'Skyjumping_ce', 'Soccer', 'Spiderman_ce', 'Suitcase_ce', 'Sunshade', 'SuperMario_ce', 'Surf_ce1', 'Surf_ce2', 'Surf_ce3', 'Surf_ce4', 'TableTennis_ce', 'TennisBall_ce', 'Tennis_ce1', 'Tennis_ce2', 'Tennis_ce3', 'Thunder_ce', 'Tiger1', 'Tiger2', 'Torus', 'Toyplane_ce', 'Trellis', 'Walking', 'Walking2', 'Woman', 'Yo-yos_ce1', 'Yo-yos_ce2', 'Yo-yos_ce3'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[dataset].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = \"Ball_ce2\"\n",
    "t1 = models[tracker]\n",
    "v1 = datasets[dataset][video]\n",
    "\n",
    "video_name = f\"{dataset}_{tracker}_{video}.avi\"\n",
    "# track_video(t1, v1, verbose=1, save_video=video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipywidgets import Video, Image\n",
    "\n",
    "# new_ = Video.from_file(video_name, play=True, width=360, height=360)\n",
    "# new_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_dataset(\n",
    "    tracker, dataset, dataset_name, n=30, verbose=0, save_results=False, overwrite=False\n",
    ") -> Tuple[float, float, float, float]:\n",
    "    \"\"\"Track a whole dataset.\n",
    "\n",
    "    Args:\n",
    "        tracker (model.Tracker): Tracker.\n",
    "        dataset (Dict): Dataset.\n",
    "        dataset_name (str): Dataset name.\n",
    "        n (int, optional): Number of videos to track. Defaults to 3.\n",
    "        verbose (int, optional): Verbosity level. Defaults to 0.\n",
    "        save_results (bool, optional): Save results. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float, float]: Mean Precisions, Successes, FPSs, Losts.\n",
    "    \"\"\"\n",
    "    result_folder = Path(\"results\")\n",
    "    if save_results:\n",
    "        (result_folder / tracker.model_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    file = result_folder / tracker.model_name / (dataset_name + \".json\")\n",
    "\n",
    "    results: Dict = {}\n",
    "    count = 0\n",
    "\n",
    "    if save_results:\n",
    "        if os.path.exists(file):\n",
    "            with open(file, 'r') as f:\n",
    "                results = json.load(f)\n",
    "\n",
    "    for video in dataset:\n",
    "        if count == n:\n",
    "            break\n",
    "        count += 1\n",
    "\n",
    "        if video in results and not overwrite:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            precisions, scores, fps, lost = track_video(tracker, dataset[video], verbose)\n",
    "            if save_results:\n",
    "                results[video] = {\"precisions\": precisions, \"scores\": scores, \"fps\": fps, \"lost\": lost}\n",
    "                with open(file, 'w') as f:\n",
    "                    json.dump(results, f, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {video}\\n{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_benchmark(models, datasets, verbose=0, save_results=False):\n",
    "    \"\"\"Benchmark a set of models on a set of datasets.\n",
    "\n",
    "    Args:\n",
    "        models (Dict): Models.\n",
    "        datasets (Dict): Datasets.\n",
    "        verbose (int, optional): Verbosity level. Defaults to 0.\n",
    "        save_results (bool, optional): Save results. Defaults to False.\n",
    "    \"\"\"\n",
    "    for model_name in models:\n",
    "        for dataset_name in datasets:\n",
    "            print(f\"Benchmarking {model_name} on {dataset_name}\")\n",
    "            track_dataset(\n",
    "                models[model_name],\n",
    "                datasets[dataset_name],\n",
    "                dataset_name,\n",
    "                verbose=verbose,\n",
    "                save_results=save_results,\n",
    "                overwrite=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Staple on mytc128\n"
     ]
    }
   ],
   "source": [
    "do_benchmark(models, datasets, verbose=1, save_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_vot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edcb81e61fb5b5265ef3ce5756b65e7049dc017a4475dd0d5299ea5731bcc364"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
