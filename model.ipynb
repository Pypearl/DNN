{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import urllib.request\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import gdown\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = Path(\"models\")\n",
    "\n",
    "models_folder.mkdir(parents=True, exist_ok=True)\n",
    "(models_folder / \"__init__.py\").touch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tracker must inherit from the `Tracker` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "import os\n",
    "\n",
    "\n",
    "class Tracker:\n",
    "    def __init__(self, model_name: str):\n",
    "        self.model_name: str = model_name\n",
    "\n",
    "    def initialize(self, image_file, box):\n",
    "        \"\"\"Initialize the tracker with the first frame and the bounding box.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def track(self, image_file):\n",
    "        \"\"\"Track the object in the next frame and return the new bounding box.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_repo(model: str, url: str):\n",
    "    \"\"\"Clone a repo from GitHub and put it in the models folder.\"\"\"\n",
    "    path_zip: Path = models_folder / (model + \".zip\")\n",
    "    dest_folder: Path = models_folder / model\n",
    "\n",
    "    if dest_folder.exists():\n",
    "        return\n",
    "\n",
    "    urllib.request.urlretrieve(url, path_zip)\n",
    "    shutil.unpack_archive(path_zip, models_folder)\n",
    "\n",
    "    try:\n",
    "        (models_folder / (model + \"-master\")).rename(dest_folder)\n",
    "    except:\n",
    "        (models_folder / (model + \"-main\")).rename(dest_folder)\n",
    "\n",
    "    path_zip.unlink()\n",
    "\n",
    "    (dest_folder / \"__init__.py\").touch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SiamSE](https://github.com/isosnovik/SiamSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"SiamSE\"\n",
    "repo_url = \"https://github.com/ISosnovik/SiamSE/archive/refs/heads/master.zip\"\n",
    "clone_repo(model, repo_url)\n",
    "\n",
    "weight_path = str(models_folder / \"SiamSE\" / \"checkpoint_vot.pth\")\n",
    "\n",
    "if not os.path.exists(weight_path):\n",
    "    weight_url = \"https://drive.google.com/uc?id=1WQ-9_QE9Xk9wj52vVcEDIXY2NBTupAnZ\"\n",
    "    gdown.download(weight_url, output=weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a model.py\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "import models.SiamSE.lib.models.models as models\n",
    "\n",
    "from pathlib import Path\n",
    "from models.SiamSE.lib.tracker import SESiamFCTracker\n",
    "from models.SiamSE.lib.utils import load_pretrain, cxy_wh_2_rect, convert_color_RGB\n",
    "from typing import *\n",
    "\n",
    "def get_SESIAMFC_tracker():\n",
    "    \n",
    "    def get_axis_aligned_bbox(bbox):\n",
    "        \"\"\"Convert bbox to [xc, yc, w, h] format\"\"\"\n",
    "        x, y, w, h = bbox\n",
    "        return [x + w / 2, y + h / 2, w, h]\n",
    "    \n",
    "    class SEsiamfc(Tracker):\n",
    "        def __init__(self):\n",
    "            super().__init__(\"SEsiamfc\")\n",
    "\n",
    "            path_SiamSE = Path('models') / 'SiamSE'\n",
    "            model_pretrained_path: Path = path_SiamSE / 'checkpoint_vot.pth'\n",
    "            config_path: Path = path_SiamSE / 'configs' / 'test.yaml'\n",
    "            \n",
    "            with open(config_path, 'r') as f:\n",
    "                tracker_config: Dict = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "\n",
    "            # Prepare model\n",
    "            net: Any = models.__dict__[tracker_config['MODEL']](padding_mode='constant')\n",
    "            net = load_pretrain(net, model_pretrained_path)\n",
    "            net = net.eval().cuda()\n",
    "\n",
    "            # Prepare tracker\n",
    "            tracker_config: Dict = tracker_config['TRACKER']['VOT2017']\n",
    "            self.tracker = SESiamFCTracker(net, **tracker_config)\n",
    "\n",
    "        def initialize(self, image_file, box):\n",
    "            # Prepare image\n",
    "            image = cv2.imread(image_file)\n",
    "            image = convert_color_RGB(image)\n",
    "            \n",
    "            # Prepare box\n",
    "            cx, cy, w, h = get_axis_aligned_bbox(box)\n",
    "            target_pos = np.array([cx, cy])\n",
    "            target_sz = np.array([w, h])\n",
    "\n",
    "            self.tracker.init(image, target_pos, target_sz)\n",
    "\n",
    "        def track(self, image_file):\n",
    "            # Prepare image\n",
    "            image = cv2.imread(image_file)\n",
    "            image = convert_color_RGB(image)\n",
    "            \n",
    "            # Track\n",
    "            target_pos, target_sz = self.tracker.track(image)\n",
    "\n",
    "            # Prepare bbox\n",
    "            return cxy_wh_2_rect(target_pos, target_sz)\n",
    "    \n",
    "    return SEsiamfc()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [PyECO](https://github.com/StrangerZhang/pyECO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"pyECO\"\n",
    "url = \"https://github.com/StrangerZhang/pyECO/archive/refs/heads/master.zip\"\n",
    "\n",
    "clone_repo(model, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marius/epita/ING3/DNN/DNN/models/pyECO/eco/features\n",
      "/home/marius/epita/ING3/DNN/DNN/models/pyECO/eco/features/setup.py:3: DeprecationWarning: \n",
      "\n",
      "  `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "  of the deprecation of `distutils` itself. It will be removed for\n",
      "  Python >= 3.12. For older Python versions it will remain present.\n",
      "  It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "  For more details, see:\n",
      "    https://numpy.org/devdocs/reference/distutils_status_migration.html \n",
      "\n",
      "\n",
      "  from numpy.distutils import misc_util\n",
      "\u001b[39mrunning build_ext\u001b[0m\n",
      "\u001b[39mbuilding '_gradient' extension\u001b[0m\n",
      "\u001b[39mWarning: Can't read registry to find the necessary compiler setting\n",
      "Make sure that Python modules winreg, win32api or win32con are installed.\u001b[0m\n",
      "\u001b[39mINFO: C compiler: gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC\n",
      "\u001b[0m\n",
      "\u001b[39mcreating build\u001b[0m\n",
      "\u001b[39mcreating build/temp.linux-x86_64-3.9\u001b[0m\n",
      "\u001b[39mINFO: compile options: '-I/home/marius/epita/ING3/DNN/DNN/venv/lib/python3.9/site-packages/numpy/core/include -I/home/marius/epita/ING3/DNN/DNN/venv/include -I/home/marius/.pyenv/versions/3.9.10/include/python3.9 -c'\u001b[0m\n",
      "\u001b[39mINFO: gcc: _gradient.cpp\u001b[0m\n",
      "\u001b[39mINFO: gcc: gradient.cpp\u001b[0m\n",
      "\u001b[01m\u001b[Kgradient.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid gradMag(float*, float*, float*, int, int, int, bool)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kgradient.cpp:76:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "         \u001b[01;35m\u001b[Kif\u001b[m\u001b[K( c==0 ) continue; _m = CMPGT( _M2[y1], _M2[y] );\n",
      "         \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kgradient.cpp:76:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "         if( c==0 ) continue; \u001b[01;36m\u001b[K_m\u001b[m\u001b[K = CMPGT( _M2[y1], _M2[y] );\n",
      "                              \u001b[01;36m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kgradient.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid gradMagNorm(float*, float*, int, int, float)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kgradient.cpp:109:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(sse) i*=4; for(; i<n; i++) M[i] /= (S[i] + norm);\n",
      "   \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kgradient.cpp:109:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "   if(sse) i*=4; \u001b[01;36m\u001b[Kfor\u001b[m\u001b[K(; i<n; i++) M[i] /= (S[i] + norm);\n",
      "                 \u001b[01;36m\u001b[K^~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/home/marius/epita/ING3/DNN/DNN/venv/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/marius/epita/ING3/DNN/DNN/venv/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/home/marius/epita/ING3/DNN/DNN/venv/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K_gradient.cpp:2\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/home/marius/epita/ING3/DNN/DNN/venv/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "\u001b[39mINFO: g++ -pthread -shared -L/home/marius/.pyenv/versions/3.9.10/lib -L/home/marius/.pyenv/versions/3.9.10/lib build/temp.linux-x86_64-3.9/_gradient.o build/temp.linux-x86_64-3.9/gradient.o -o /home/marius/epita/ING3/DNN/DNN/models/pyECO/eco/features/_gradient.cpython-39-x86_64-linux-gnu.so\u001b[0m\n",
      "/home/marius/epita/ING3/DNN/DNN\n"
     ]
    }
   ],
   "source": [
    "if not (models_folder / model / \"eco\" / \"features\" / \"_gradient.cpython-310-x86_64-linux-gnu.so\").exists():\n",
    "    %cd models/pyECO/eco/features/\n",
    "    !python setup.py build_ext --inplace\n",
    "    %cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model.py\n"
     ]
    }
   ],
   "source": [
    "%%file -a model.py\n",
    "\n",
    "def get_PyECO_tracker():\n",
    "    os.sys.path.append('models/pyECO')\n",
    "    from eco import ECOTracker\n",
    "    \n",
    "    class PyECO(Tracker):\n",
    "        def __init__(self):\n",
    "            super().__init__(\"PyECO\")\n",
    "            self.tracker = ECOTracker(True)\n",
    "\n",
    "        def initialize(self, image_file, box):\n",
    "            image = cv2.imread(image_file)\n",
    "            self.tracker.init(image, box)\n",
    "\n",
    "        def track(self, image_file):\n",
    "            image = cv2.imread(image_file)\n",
    "            extremities = self.tracker.update(image)\n",
    "            bbox = [extremities[0], extremities[1], extremities[2] - extremities[0], extremities[3] - extremities[1]]\n",
    "            return bbox\n",
    "    \n",
    "    return PyECO()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MixFormer](https://github.com/MCG-NJU/MixFormer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"MixFormer\"\n",
    "url = \"https://github.com/Sefray/MixFormer/archive/refs/heads/master.zip\"\n",
    "\n",
    "clone_repo(model, url)\n",
    "\n",
    "weight_file = 'mixformer_online_22k.pth.tar'\n",
    "weight_path = str(models_folder / \"Mixformer\" / weight_file)\n",
    "\n",
    "if not os.path.exists(weight_path):\n",
    "    weight_url = \"https://drive.google.com/uc?id=1-UonqFXM-jKNnkJmN8lSEczeaKiNVxeh\"\n",
    "    gdown.download(weight_url, output=weight_path)\n",
    "\n",
    "    %cd models/MixFormer/\n",
    "    !python tracking/create_default_local_file.py --workspace_dir . --data_dir ./data --save_dir .\n",
    "    %cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model.py\n"
     ]
    }
   ],
   "source": [
    "%%file -a model.py\n",
    "\n",
    "def get_MixFormer_tracker():\n",
    "    os.sys.path.append('models/MixFormer')\n",
    "    from lib.test.tracker.mixformer import MixFormer as MF\n",
    "    import importlib\n",
    "    class MixFormer(Tracker):\n",
    "        def __init__(self):\n",
    "            super().__init__(\"MixFormer\")\n",
    "            \n",
    "            tracker_params = {}\n",
    "            tracker_params['model'] = 'mixformer_online_22k.pth.tar'\n",
    "            tracker_params['max_score_decay'] = 1.0\n",
    "            tracker_params['vis_attn'] = 0\n",
    "\n",
    "            param_module = importlib.import_module('lib.test.parameter.mixformer')\n",
    "            search_area_scale = None\n",
    "            if tracker_params is not None and 'search_area_scale' in tracker_params:\n",
    "                search_area_scale = tracker_params['search_area_scale']\n",
    "            model = ''\n",
    "            if tracker_params is not None and 'model' in tracker_params:\n",
    "                model = tracker_params['model']\n",
    "            params = param_module.parameters('baseline', model, search_area_scale)\n",
    "            if tracker_params is not None:\n",
    "                for param_k, v in tracker_params.items():\n",
    "                    setattr(params, param_k, v)\n",
    "            \n",
    "            self.tracker = MF(params)\n",
    "\n",
    "        def initialize(self, image_file, box):\n",
    "            image = cv2.imread(image_file)\n",
    "            info = {'init_bbox': box}\n",
    "            self.tracker.initialize(image, info)\n",
    "\n",
    "        def track(self, image_file):\n",
    "            image = cv2.imread(image_file)\n",
    "            info = self.tracker.track(image)\n",
    "            return info['target_bbox']\n",
    "\n",
    "    return MixFormer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MDNet](https://github.com/hyeonseobnam/py-MDNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"py-MDNet\"\n",
    "url = \"https://github.com/noTban/py-MDNet/archive/refs/heads/master.zip\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have a GPU, change *use_gpu* to *false* in models/py-MDNet/tracking/options.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_repo(model, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pyMDNet_tracker():\n",
    "    os.sys.path.append('models/py-MDNet')\n",
    "    from modules.model import MDNet, BCELoss, set_optimizer\n",
    "    from modules.sample_generator import SampleGenerator\n",
    "    from modules.utils import overlap_ratio\n",
    "    from tracking.bbreg import BBRegressor\n",
    "    from tracking.data_prov import RegionExtractor\n",
    "    from tracking.gen_config import gen_config\n",
    "    import cv2\n",
    "    import yaml\n",
    "    import torch\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    \n",
    "    \n",
    "    class pyMDNet(Tracker):\n",
    "        def __init__(self):\n",
    "            super().__init__(\"pyMDNet\")\n",
    "            self.opts = yaml.safe_load(open('models/py-MDNet/tracking/options.yaml','r'))\n",
    "            self.tracker = MDNet('models/py-MDNet/models/mdnet_imagenet_vid.pth')\n",
    "            if self.opts['use_gpu']:\n",
    "                self.tracker = self.tracker.cuda()\n",
    "            self.target_bbox = None\n",
    "            self.sample_generator = None\n",
    "            self.pos_generator = None\n",
    "            self.neg_generator = None\n",
    "            self.pos_feats_all = None\n",
    "            self.neg_feats_all = None\n",
    "            self.bbreg = None\n",
    "            self.criterion = BCELoss()\n",
    "            self.i = 0\n",
    "            \n",
    "        def forward_samples(self, image, samples, out_layer='conv3'):\n",
    "            self.tracker.eval()\n",
    "            extractor = RegionExtractor(image, samples, self.opts)\n",
    "            for i, regions in enumerate(extractor):\n",
    "                if self.opts['use_gpu']:\n",
    "                    regions = regions.cuda()\n",
    "                with torch.no_grad():\n",
    "                    feat = self.tracker(regions, out_layer=out_layer)\n",
    "                if i==0:\n",
    "                    feats = feat.detach().clone()\n",
    "                else:\n",
    "                    feats = torch.cat((feats, feat.detach().clone()), 0)\n",
    "            return feats\n",
    "   \n",
    "        def train(self, optimizer, pos_feats, neg_feats, maxiter, in_layer='fc4'):\n",
    "            self.tracker.train()\n",
    "\n",
    "            batch_pos = self.opts['batch_pos']\n",
    "            batch_neg = self.opts['batch_neg']\n",
    "            batch_test = self.opts['batch_test']\n",
    "            batch_neg_cand = max(self.opts['batch_neg_cand'], batch_neg)\n",
    "\n",
    "            pos_idx = np.random.permutation(pos_feats.size(0))\n",
    "            neg_idx = np.random.permutation(neg_feats.size(0))\n",
    "            while(len(pos_idx) < batch_pos * maxiter):\n",
    "                pos_idx = np.concatenate([pos_idx, np.random.permutation(pos_feats.size(0))])\n",
    "            while(len(neg_idx) < batch_neg_cand * maxiter):\n",
    "                neg_idx = np.concatenate([neg_idx, np.random.permutation(neg_feats.size(0))])\n",
    "            pos_pointer = 0\n",
    "            neg_pointer = 0\n",
    "\n",
    "            for _ in range(maxiter):\n",
    "\n",
    "                # select pos idx\n",
    "                pos_next = pos_pointer + batch_pos\n",
    "                pos_cur_idx = pos_idx[pos_pointer:pos_next]\n",
    "                pos_cur_idx = pos_feats.new(pos_cur_idx).long()\n",
    "                pos_pointer = pos_next\n",
    "\n",
    "                # select neg idx\n",
    "                neg_next = neg_pointer + batch_neg_cand\n",
    "                neg_cur_idx = neg_idx[neg_pointer:neg_next]\n",
    "                neg_cur_idx = neg_feats.new(neg_cur_idx).long()\n",
    "                neg_pointer = neg_next\n",
    "\n",
    "                # create batch\n",
    "                batch_pos_feats = pos_feats[pos_cur_idx]\n",
    "                batch_neg_feats = neg_feats[neg_cur_idx]\n",
    "\n",
    "                # hard negative mining\n",
    "                if batch_neg_cand > batch_neg:\n",
    "                    self.tracker.eval()\n",
    "                    for start in range(0, batch_neg_cand, batch_test):\n",
    "                        end = min(start + batch_test, batch_neg_cand)\n",
    "                        with torch.no_grad():\n",
    "                            score = self.tracker(batch_neg_feats[start:end], in_layer=in_layer)\n",
    "                        if start==0:\n",
    "                            neg_cand_score = score.detach()[:, 1].clone()\n",
    "                        else:\n",
    "                            neg_cand_score = torch.cat((neg_cand_score, score.detach()[:, 1].clone()), 0)\n",
    "\n",
    "                    _, top_idx = neg_cand_score.topk(batch_neg)\n",
    "                    batch_neg_feats = batch_neg_feats[top_idx]\n",
    "                    self.tracker.train()\n",
    "\n",
    "                # forward\n",
    "                pos_score = self.tracker(batch_pos_feats, in_layer=in_layer)\n",
    "                neg_score = self.tracker(batch_neg_feats, in_layer=in_layer)\n",
    "\n",
    "                # optimize\n",
    "                loss = self.criterion(pos_score, neg_score)\n",
    "                self.tracker.zero_grad()\n",
    "                loss.backward()\n",
    "                if 'grad_clip' in self.opts:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.tracker.parameters(), self.opts['grad_clip'])\n",
    "                optimizer.step()\n",
    "\n",
    "        def initialize(self, image_file, box):\n",
    "            self.i += 1\n",
    "            image = Image.open(image_file).convert('RGB')\n",
    "\n",
    "            self.target_bbox = np.array(box)\n",
    "\n",
    "            # Init self.criterion and optimizer \n",
    "            self.tracker.set_learnable_params(self.opts['ft_layers'])\n",
    "            init_optimizer = set_optimizer(self.tracker, self.opts['lr_init'], self.opts['lr_mult'])\n",
    "            self.update_optimizer = set_optimizer(self.tracker, self.opts['lr_update'], self.opts['lr_mult'])\n",
    "\n",
    "            # Draw pos/neg samples\n",
    "            pos_examples = SampleGenerator('gaussian', image.size, self.opts['trans_pos'], self.opts['scale_pos'])(\n",
    "                                self.target_bbox, self.opts['n_pos_init'], self.opts['overlap_pos_init'])\n",
    "\n",
    "            neg_examples = np.concatenate([\n",
    "                            SampleGenerator('uniform', image.size, self.opts['trans_neg_init'], self.opts['scale_neg_init'])(\n",
    "                                self.target_bbox, int(self.opts['n_neg_init'] * 0.5), self.opts['overlap_neg_init']),\n",
    "                            SampleGenerator('whole', image.size)(\n",
    "                                self.target_bbox, int(self.opts['n_neg_init'] * 0.5), self.opts['overlap_neg_init'])])\n",
    "            neg_examples = np.random.permutation(neg_examples)\n",
    "\n",
    "            # Extract pos/neg features\n",
    "            pos_feats = self.forward_samples(image, pos_examples)\n",
    "            neg_feats = self.forward_samples(image, neg_examples)\n",
    "\n",
    "            # Initial training\n",
    "            self.train(init_optimizer, pos_feats, neg_feats, self.opts['maxiter_init'])\n",
    "            del init_optimizer, neg_feats\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # Train bbox regressor\n",
    "            bbreg_examples = SampleGenerator('uniform', image.size, self.opts['trans_bbreg'], self.opts['scale_bbreg'], self.opts['aspect_bbreg'])(\n",
    "                                self.target_bbox, self.opts['n_bbreg'], self.opts['overlap_bbreg'])\n",
    "            bbreg_feats = self.forward_samples(image, bbreg_examples)\n",
    "            self.bbreg = BBRegressor(image.size)\n",
    "            self.bbreg.train(bbreg_feats, bbreg_examples, self.target_bbox)\n",
    "            del bbreg_feats\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # Init sample generators for update\n",
    "            self.sample_generator = SampleGenerator('gaussian', image.size, self.opts['trans'], self.opts['scale'])\n",
    "            self.pos_generator = SampleGenerator('gaussian', image.size, self.opts['trans_pos'], self.opts['scale_pos'])\n",
    "            self.neg_generator = SampleGenerator('uniform', image.size, self.opts['trans_neg'], self.opts['scale_neg'])\n",
    "\n",
    "            # Init pos/neg features for update\n",
    "            neg_examples = self.neg_generator(self.target_bbox, self.opts['n_neg_update'], self.opts['overlap_neg_init'])\n",
    "            neg_feats = self.forward_samples(image, neg_examples)\n",
    "            self.pos_feats_all = [pos_feats]\n",
    "            self.neg_feats_all = [neg_feats]\n",
    "\n",
    "        def track(self, image_file):\n",
    "            self.i +=1\n",
    "            image = Image.open(image_file).convert('RGB')\n",
    "\n",
    "            # Estimate target bbox\n",
    "            samples = self.sample_generator(self.target_bbox, self.opts['n_samples'])\n",
    "            sample_scores = self.forward_samples(image, samples, out_layer='fc6')\n",
    "\n",
    "            top_scores, top_idx = sample_scores[:, 1].topk(5)\n",
    "            top_idx = top_idx.cpu()\n",
    "            target_score = top_scores.mean()\n",
    "            self.target_bbox = samples[top_idx]\n",
    "            if top_idx.shape[0] > 1:\n",
    "                self.target_bbox = self.target_bbox.mean(axis=0)\n",
    "            success = target_score > 0\n",
    "                \n",
    "            # Expand search area at failure\n",
    "            if success:\n",
    "                self.sample_generator.set_trans(self.opts['trans'])\n",
    "            else:\n",
    "                self.sample_generator.expand_trans(self.opts['trans_limit'])\n",
    "\n",
    "            # Bbox regression\n",
    "            if success:\n",
    "                bbreg_samples = samples[top_idx]\n",
    "                if top_idx.shape[0] == 1:\n",
    "                    bbreg_samples = bbreg_samples[None,:]\n",
    "                bbreg_feats = self.forward_samples(image, bbreg_samples)\n",
    "                bbreg_samples = self.bbreg.predict(bbreg_feats, bbreg_samples)\n",
    "                bbreg_bbox = bbreg_samples.mean(axis=0)\n",
    "            else:\n",
    "                bbreg_bbox = self.target_bbox\n",
    "\n",
    "            # Data collect\n",
    "            if success:\n",
    "                pos_examples = self.pos_generator(self.target_bbox, self.opts['n_pos_update'], self.opts['overlap_pos_update'])\n",
    "                pos_feats = self.forward_samples(image, pos_examples)\n",
    "                self.pos_feats_all.append(pos_feats)\n",
    "                if len(self.pos_feats_all) > self.opts['n_frames_long']:\n",
    "                    del self.pos_feats_all[0]\n",
    "\n",
    "                neg_examples = self.neg_generator(self.target_bbox, self.opts['n_neg_update'], self.opts['overlap_neg_update'])\n",
    "                neg_feats = self.forward_samples(image, neg_examples)\n",
    "                self.neg_feats_all.append(neg_feats)\n",
    "                if len(self.neg_feats_all) > self.opts['n_frames_short']:\n",
    "                    del self.neg_feats_all[0]\n",
    "\n",
    "            # Short term update\n",
    "            if not success:\n",
    "                nframes = min(self.opts['n_frames_short'], len(self.pos_feats_all))\n",
    "                pos_data = torch.cat(self.pos_feats_all[-nframes:], 0)\n",
    "                neg_data = torch.cat(self.neg_feats_all, 0)\n",
    "                self.train( self.update_optimizer, pos_data, neg_data, self.opts['maxiter_update'])\n",
    "\n",
    "            # Long term update\n",
    "            elif self.i % self.opts['long_interval'] == 0:\n",
    "                pos_data = torch.cat(self.pos_feats_all, 0)\n",
    "                neg_data = torch.cat(self.neg_feats_all, 0)\n",
    "                self.train( self.update_optimizer, pos_data, neg_data, self.opts['maxiter_update'])\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            return bbreg_bbox\n",
    "    \n",
    "    return pyMDNet()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [AAA](https://github.com/songheony/A3T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"A3T\"\n",
    "url = \"https://github.com/Leiyks/A3T/archive/refs/heads/master.zip\"\n",
    "\n",
    "clone_repo(model, url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tracker is a bagging tracker. It uses the tracks of other trackers to make its own predictions. In our testing, we will try to see if the trackers using all the trackers we are testing is better then them individually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (models_folder / \"A3T\" / \"pysot-toolkit\").exists():\n",
    "    %cd models/A3T\n",
    "\n",
    "    # clone frameworks\n",
    "    !git clone https://github.com/songheony/pytracking.git\n",
    "    !git clone https://github.com/StrangerZhang/pysot-toolkit\n",
    "\n",
    "    # install region\n",
    "    %cd pysot-toolkit/pysot/utils/\n",
    "    !python setup.py build_ext --inplace\n",
    "    %cd ../../../../../\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some modification on the path used has to be performed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a model.py\n",
    "\n",
    "def get_AAA_tracker():\n",
    "    import numpy as np\n",
    "    class AAA(Tracker):\n",
    "        def __init__(self):\n",
    "            super().__init__(\"AAA\")\n",
    "            import models.A3T.algorithms.aaa as aaa\n",
    "            self.experts = [\n",
    "                get_SESIAMFC_tracker(),\n",
    "                get_PyECO_tracker(),\n",
    "                get_MixFormer_tracker(),\n",
    "            ]\n",
    "            self.n_experts = len(self.experts) # number of experts\n",
    "            theta, gamma = 0.92, 11  # you can tune hyperparameters by running run_tuning.sh\n",
    "            self.tracker = aaa.AAA(self.n_experts, mode=\"LOG_DIR\", threshold=theta)\n",
    "\n",
    "\n",
    "        def initialize(self, image_path, bbox):\n",
    "            for i in range(self.n_experts):\n",
    "                self.experts[i].initialize(image_path, bbox)\n",
    "            self.tracker.initialize(image_path, bbox)\n",
    "\n",
    "        def track(self, image_path):\n",
    "            experts_result = np.zeros((self.n_experts, 4))\n",
    "            for i in range(self.n_experts):\n",
    "                experts_result[i, :] = self.experts[i].track(image_path)\n",
    "            state, offline, weight = self.tracker.track(image_path, experts_result)\n",
    "            return state\n",
    "  \n",
    "    return AAA()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a model.py\n",
    "\n",
    "def load_models() -> Dict[str, Tracker]:\n",
    "    \"\"\"Load all models\n",
    "    Returns:\n",
    "        Dict[str, Tracker]: Dict of models\n",
    "    \"\"\"\n",
    "    ret: Dict[str, Tracker] = {}\n",
    "    \n",
    "    # ret['SEsiamFC'] = get_SESIAMFC_tracker()\n",
    "    # ret['AAA'] = get_AAA_tracker()\n",
    "    # ret['PyECO'] = get_PyECO_tracker()\n",
    "    # ret['MixFormer'] = get_MixFormer_tracker()\n",
    "    ret['pyMDNet'] = get_pyMDNet_tracker()\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d9252bccb5f40923e9b4c4ab41ecaa42058158df6f26a83ec92f94020728ac1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
