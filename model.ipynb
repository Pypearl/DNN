{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import urllib.request\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "import gdown\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = Path(\"models\")\n",
    "\n",
    "models_folder.mkdir(parents=True, exist_ok=True)\n",
    "(models_folder / \"__init__.py\").touch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tracker must inherit from the `Tracker` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "import os\n",
    "from typing import *\n",
    "import cv2\n",
    "\n",
    "class Tracker:\n",
    "    def __init__(self, model_name: str):\n",
    "        self.model_name: str = model_name\n",
    "\n",
    "    def initialize(self, image_file, box):\n",
    "        \"\"\"Initialize the tracker with the first frame and the bounding box.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def track(self, image_file):\n",
    "        \"\"\"Track the object in the next frame and return the new bounding box.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clone_repo(model: str, url: str):\n",
    "    \"\"\"Clone a repo from GitHub and put it in the models folder.\"\"\"\n",
    "    path_zip: Path = models_folder / (model + \".zip\")\n",
    "    dest_folder: Path = models_folder / model\n",
    "\n",
    "    if dest_folder.exists():\n",
    "        return\n",
    "\n",
    "    urllib.request.urlretrieve(url, path_zip)\n",
    "    shutil.unpack_archive(path_zip, models_folder)\n",
    "\n",
    "    try:\n",
    "        (models_folder / (model + \"-master\")).rename(dest_folder)\n",
    "    except:\n",
    "        (models_folder / (model + \"-main\")).rename(dest_folder)\n",
    "\n",
    "    path_zip.unlink()\n",
    "\n",
    "    (dest_folder / \"__init__.py\").touch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Staple](https://arxiv.org/pdf/1512.01355v2.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"pyCFTrackers\"\n",
    "url = \"https://github.com/noTban/pyCFTrackers/archive/refs/heads/master.zip\"\n",
    "\n",
    "clone_repo(model, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/Documents/DNN_project/projet/models/pyCFTrackers\n",
      "/mnt/d/Documents/DNN_project/projet/models/pyCFTrackers/libs/eco/features\n",
      "/mnt/d/Documents/DNN_project/projet/models/pyCFTrackers/libs/eco/features/setup.py:2: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  from distutils.core import setup, Extension\n",
      "/mnt/d/Documents/DNN_project/projet/models/pyCFTrackers/libs/eco/features/setup.py:3: DeprecationWarning: \n",
      "\n",
      "  `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "  of the deprecation of `distutils` itself. It will be removed for\n",
      "  Python >= 3.12. For older Python versions it will remain present.\n",
      "  It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "  For more details, see:\n",
      "    https://numpy.org/devdocs/reference/distutils_status_migration.html \n",
      "\n",
      "\n",
      "  from numpy.distutils import misc_util\n",
      "\u001b[39mrunning build_ext\u001b[0m\n",
      "/mnt/d/Documents/DNN_project/projet/models/pyCFTrackers\n",
      "/mnt/d/Documents/DNN_project/projet/models/pyCFTrackers/libs/pysot/utils\n",
      "/mnt/d/Documents/DNN_project/projet/models/pyCFTrackers/libs/pysot/utils/setup.py:1: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  from distutils.core import setup\n",
      "running build_ext\n",
      "/mnt/d/Documents/DNN_project/projet/models/pyCFTrackers\n",
      "/mnt/d/Documents/DNN_project/projet\n"
     ]
    }
   ],
   "source": [
    "%cd models/pyCFTrackers\n",
    "# install region\n",
    "%cd libs/eco/features/\n",
    "!python setup.py build_ext --inplace\n",
    "%cd ../../..\n",
    "\n",
    "%cd libs/pysot/utils/\n",
    "!python setup.py build_ext --inplace\n",
    "%cd ../../..\n",
    "\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model.py\n"
     ]
    }
   ],
   "source": [
    "%%file -a model.py\n",
    "\n",
    "def get_Staple_tracker():\n",
    "    os.sys.path.append('models/pyCFTrackers')\n",
    "    from cftracker.staple import Staple\n",
    "    from cftracker.config import staple_config\n",
    "    class StapleTracker(Tracker):\n",
    "        def __init__(self):\n",
    "            super().__init__(\"Staple\")\n",
    "            self.tracker = Staple(config=staple_config.StapleConfig())\n",
    "\n",
    "        def initialize(self, image_file, box):\n",
    "            image = cv2.imread(image_file)\n",
    "            self.tracker.init(image, box)\n",
    "\n",
    "        def track(self, image_file):\n",
    "            image = cv2.imread(image_file)\n",
    "            bbox = self.tracker.update(image)\n",
    "            return bbox\n",
    "    \n",
    "    return StapleTracker()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SiamSE](https://github.com/isosnovik/SiamSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"SiamSE\"\n",
    "repo_url = \"https://github.com/ISosnovik/SiamSE/archive/refs/heads/master.zip\"\n",
    "clone_repo(model, repo_url)\n",
    "\n",
    "weight_path = str(models_folder / \"SiamSE\" / \"checkpoint_vot.pth\")\n",
    "\n",
    "if not os.path.exists(weight_path):\n",
    "    weight_url = \"https://drive.google.com/uc?id=1WQ-9_QE9Xk9wj52vVcEDIXY2NBTupAnZ\"\n",
    "    gdown.download(weight_url, output=weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a model.py\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "import models.SiamSE.lib.models.models as models\n",
    "\n",
    "from pathlib import Path\n",
    "from models.SiamSE.lib.tracker import SESiamFCTracker\n",
    "from models.SiamSE.lib.utils import load_pretrain, cxy_wh_2_rect, convert_color_RGB\n",
    "from typing import *\n",
    "\n",
    "def get_SESIAMFC_tracker():\n",
    "    \n",
    "    def get_axis_aligned_bbox(bbox):\n",
    "        \"\"\"Convert bbox to [xc, yc, w, h] format\"\"\"\n",
    "        x, y, w, h = bbox\n",
    "        return [x + w / 2, y + h / 2, w, h]\n",
    "    \n",
    "    class SEsiamfc(Tracker):\n",
    "        def __init__(self):\n",
    "            super().__init__(\"SEsiamfc\")\n",
    "\n",
    "            path_SiamSE = Path('models') / 'SiamSE'\n",
    "            model_pretrained_path: Path = path_SiamSE / 'checkpoint_vot.pth'\n",
    "            config_path: Path = path_SiamSE / 'configs' / 'test.yaml'\n",
    "            \n",
    "            with open(config_path, 'r') as f:\n",
    "                tracker_config: Dict = yaml.load(f.read(), Loader=yaml.FullLoader)\n",
    "\n",
    "            # Prepare model\n",
    "            net: Any = models.__dict__[tracker_config['MODEL']](padding_mode='constant')\n",
    "            net = load_pretrain(net, model_pretrained_path)\n",
    "            net = net.eval().cuda()\n",
    "\n",
    "            # Prepare tracker\n",
    "            tracker_config: Dict = tracker_config['TRACKER']['VOT2017']\n",
    "            self.tracker = SESiamFCTracker(net, **tracker_config)\n",
    "\n",
    "        def initialize(self, image_file, box):\n",
    "            # Prepare image\n",
    "            image = cv2.imread(image_file)\n",
    "            image = convert_color_RGB(image)\n",
    "            \n",
    "            # Prepare box\n",
    "            cx, cy, w, h = get_axis_aligned_bbox(box)\n",
    "            target_pos = np.array([cx, cy])\n",
    "            target_sz = np.array([w, h])\n",
    "\n",
    "            self.tracker.init(image, target_pos, target_sz)\n",
    "\n",
    "        def track(self, image_file):\n",
    "            # Prepare image\n",
    "            image = cv2.imread(image_file)\n",
    "            image = convert_color_RGB(image)\n",
    "            \n",
    "            # Track\n",
    "            target_pos, target_sz = self.tracker.track(image)\n",
    "\n",
    "            # Prepare bbox\n",
    "            return cxy_wh_2_rect(target_pos, target_sz)\n",
    "    \n",
    "    return SEsiamfc()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [PyECO]((https://github.com/StrangerZhang/pyECO)) - Hand-crafted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"pyECO\"\n",
    "url = \"https://github.com/StrangerZhang/pyECO/archive/refs/heads/master.zip\"\n",
    "\n",
    "clone_repo(model, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (models_folder / model / \"eco\" / \"features\" / \"_gradient.cpython-310-x86_64-linux-gnu.so\").exists():\n",
    "    %cd models/pyECO/eco/features/\n",
    "    !python setup.py build_ext --inplace\n",
    "    %cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model.py\n"
     ]
    }
   ],
   "source": [
    "%%file -a model.py\n",
    "\n",
    "def get_PyECO_tracker(model_name=\"pyECO\"):\n",
    "    os.sys.path.append('models/' + model_name)\n",
    "    from eco import ECOTracker\n",
    "    \n",
    "    class PyECO(Tracker):\n",
    "        def __init__(self):\n",
    "            super().__init__(model_name)\n",
    "            self.tracker = ECOTracker(True)\n",
    "\n",
    "        def initialize(self, image_file, box):\n",
    "            image = cv2.imread(image_file)\n",
    "            self.tracker.init(image, box)\n",
    "\n",
    "        def track(self, image_file):\n",
    "            image = cv2.imread(image_file)\n",
    "            extremities = self.tracker.update(image)\n",
    "            bbox = [extremities[0], extremities[1], extremities[2] - extremities[0], extremities[3] - extremities[1]]\n",
    "            return bbox\n",
    "    \n",
    "    return PyECO()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [PyECO]((https://github.com/StrangerZhang/pyECO)) - Deep features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"pyECO_deep\"\n",
    "url = \"https://github.com/noTban/pyECO_deep/archive/refs/heads/master.zip\"\n",
    "\n",
    "clone_repo(model, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (models_folder / model / \"eco\" / \"features\" / \"_gradient.cpython-310-x86_64-linux-gnu.so\").exists():\n",
    "    %cd models/pyECO_deep/eco/features/\n",
    "    !python setup.py build_ext --inplace\n",
    "    %cd -"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MixFormer](https://github.com/MCG-NJU/MixFormer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"MixFormer\"\n",
    "url = \"https://github.com/Sefray/MixFormer/archive/refs/heads/master.zip\"\n",
    "\n",
    "clone_repo(model, url)\n",
    "\n",
    "weight_file = 'mixformer_online_22k.pth.tar'\n",
    "weight_path = str(models_folder / \"MixFormer\" / weight_file)\n",
    "\n",
    "if not os.path.exists(weight_path):\n",
    "    weight_url = \"https://drive.google.com/uc?id=1-UonqFXM-jKNnkJmN8lSEczeaKiNVxeh\"\n",
    "    gdown.download(weight_url, output=weight_path)\n",
    "\n",
    "    %cd models/MixFormer/\n",
    "    !python tracking/create_default_local_file.py --workspace_dir . --data_dir ./data --save_dir .\n",
    "    %cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model.py\n"
     ]
    }
   ],
   "source": [
    "%%file -a model.py\n",
    "\n",
    "def get_MixFormer_tracker():\n",
    "    os.sys.path.append('models/MixFormer')\n",
    "    from lib.test.tracker.mixformer import MixFormer as MF\n",
    "    import importlib\n",
    "    class MixFormer(Tracker):\n",
    "        def __init__(self):\n",
    "            super().__init__(\"MixFormer\")\n",
    "            \n",
    "            tracker_params = {}\n",
    "            tracker_params['model'] = 'mixformer_online_22k.pth.tar'\n",
    "            tracker_params['max_score_decay'] = 1.0\n",
    "            tracker_params['vis_attn'] = 0\n",
    "\n",
    "            param_module = importlib.import_module('lib.test.parameter.mixformer')\n",
    "            search_area_scale = None\n",
    "            if tracker_params is not None and 'search_area_scale' in tracker_params:\n",
    "                search_area_scale = tracker_params['search_area_scale']\n",
    "            model = ''\n",
    "            if tracker_params is not None and 'model' in tracker_params:\n",
    "                model = tracker_params['model']\n",
    "            params = param_module.parameters('baseline', model, search_area_scale)\n",
    "            if tracker_params is not None:\n",
    "                for param_k, v in tracker_params.items():\n",
    "                    setattr(params, param_k, v)\n",
    "            \n",
    "            self.tracker = MF(params)\n",
    "\n",
    "        def initialize(self, image_file, box):\n",
    "            image = cv2.imread(image_file)\n",
    "            info = {'init_bbox': box}\n",
    "            self.tracker.initialize(image, info)\n",
    "\n",
    "        def track(self, image_file):\n",
    "            image = cv2.imread(image_file)\n",
    "            info = self.tracker.track(image)\n",
    "            return info['target_bbox']\n",
    "\n",
    "    return MixFormer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MDNet](https://github.com/hyeonseobnam/py-MDNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"py-MDNet\"\n",
    "url = \"https://github.com/noTban/py-MDNet/archive/refs/heads/master.zip\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have a GPU, change *use_gpu* to *false* in models/py-MDNet/tracking/options.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_repo(model, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model.py\n"
     ]
    }
   ],
   "source": [
    "%%file -a model.py\n",
    "\n",
    "def get_pyMDNet_tracker():\n",
    "    os.sys.path.append('models/py-MDNet')\n",
    "    from modules.model import MDNet, BCELoss, set_optimizer\n",
    "    from modules.sample_generator import SampleGenerator\n",
    "    from modules.utils import overlap_ratio\n",
    "    from tracking.bbreg import BBRegressor\n",
    "    from tracking.data_prov import RegionExtractor\n",
    "    from tracking.gen_config import gen_config\n",
    "    import cv2\n",
    "    import yaml\n",
    "    import torch\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    \n",
    "    \n",
    "    class pyMDNet(Tracker):\n",
    "        def __init__(self):\n",
    "            super().__init__(\"pyMDNet\")\n",
    "            self.opts = yaml.safe_load(open('models/py-MDNet/tracking/options.yaml','r'))\n",
    "            self.tracker = MDNet('models/py-MDNet/models/mdnet_imagenet_vid.pth')\n",
    "            if self.opts['use_gpu']:\n",
    "                self.tracker = self.tracker.cuda()\n",
    "            self.target_bbox = None\n",
    "            self.sample_generator = None\n",
    "            self.pos_generator = None\n",
    "            self.neg_generator = None\n",
    "            self.pos_feats_all = None\n",
    "            self.neg_feats_all = None\n",
    "            self.bbreg = None\n",
    "            self.criterion = BCELoss()\n",
    "            self.i = 0\n",
    "            \n",
    "        def forward_samples(self, image, samples, out_layer='conv3'):\n",
    "            self.tracker.eval()\n",
    "            extractor = RegionExtractor(image, samples, self.opts)\n",
    "            for i, regions in enumerate(extractor):\n",
    "                if self.opts['use_gpu']:\n",
    "                    regions = regions.cuda()\n",
    "                with torch.no_grad():\n",
    "                    feat = self.tracker(regions, out_layer=out_layer)\n",
    "                if i==0:\n",
    "                    feats = feat.detach().clone()\n",
    "                else:\n",
    "                    feats = torch.cat((feats, feat.detach().clone()), 0)\n",
    "            return feats\n",
    "   \n",
    "        def train(self, optimizer, pos_feats, neg_feats, maxiter, in_layer='fc4'):\n",
    "            self.tracker.train()\n",
    "\n",
    "            batch_pos = self.opts['batch_pos']\n",
    "            batch_neg = self.opts['batch_neg']\n",
    "            batch_test = self.opts['batch_test']\n",
    "            batch_neg_cand = max(self.opts['batch_neg_cand'], batch_neg)\n",
    "\n",
    "            pos_idx = np.random.permutation(pos_feats.size(0))\n",
    "            neg_idx = np.random.permutation(neg_feats.size(0))\n",
    "            while(len(pos_idx) < batch_pos * maxiter):\n",
    "                pos_idx = np.concatenate([pos_idx, np.random.permutation(pos_feats.size(0))])\n",
    "            while(len(neg_idx) < batch_neg_cand * maxiter):\n",
    "                neg_idx = np.concatenate([neg_idx, np.random.permutation(neg_feats.size(0))])\n",
    "            pos_pointer = 0\n",
    "            neg_pointer = 0\n",
    "\n",
    "            for _ in range(maxiter):\n",
    "\n",
    "                # select pos idx\n",
    "                pos_next = pos_pointer + batch_pos\n",
    "                pos_cur_idx = pos_idx[pos_pointer:pos_next]\n",
    "                pos_cur_idx = pos_feats.new(pos_cur_idx).long()\n",
    "                pos_pointer = pos_next\n",
    "\n",
    "                # select neg idx\n",
    "                neg_next = neg_pointer + batch_neg_cand\n",
    "                neg_cur_idx = neg_idx[neg_pointer:neg_next]\n",
    "                neg_cur_idx = neg_feats.new(neg_cur_idx).long()\n",
    "                neg_pointer = neg_next\n",
    "\n",
    "                # create batch\n",
    "                batch_pos_feats = pos_feats[pos_cur_idx]\n",
    "                batch_neg_feats = neg_feats[neg_cur_idx]\n",
    "\n",
    "                # hard negative mining\n",
    "                if batch_neg_cand > batch_neg:\n",
    "                    self.tracker.eval()\n",
    "                    for start in range(0, batch_neg_cand, batch_test):\n",
    "                        end = min(start + batch_test, batch_neg_cand)\n",
    "                        with torch.no_grad():\n",
    "                            score = self.tracker(batch_neg_feats[start:end], in_layer=in_layer)\n",
    "                        if start==0:\n",
    "                            neg_cand_score = score.detach()[:, 1].clone()\n",
    "                        else:\n",
    "                            neg_cand_score = torch.cat((neg_cand_score, score.detach()[:, 1].clone()), 0)\n",
    "\n",
    "                    _, top_idx = neg_cand_score.topk(batch_neg)\n",
    "                    batch_neg_feats = batch_neg_feats[top_idx]\n",
    "                    self.tracker.train()\n",
    "\n",
    "                # forward\n",
    "                pos_score = self.tracker(batch_pos_feats, in_layer=in_layer)\n",
    "                neg_score = self.tracker(batch_neg_feats, in_layer=in_layer)\n",
    "\n",
    "                # optimize\n",
    "                loss = self.criterion(pos_score, neg_score)\n",
    "                self.tracker.zero_grad()\n",
    "                loss.backward()\n",
    "                if 'grad_clip' in self.opts:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.tracker.parameters(), self.opts['grad_clip'])\n",
    "                optimizer.step()\n",
    "\n",
    "        def initialize(self, image_file, box):\n",
    "            self.i += 1\n",
    "            image = Image.open(image_file).convert('RGB')\n",
    "\n",
    "            self.target_bbox = np.array(box)\n",
    "\n",
    "            # Init self.criterion and optimizer \n",
    "            self.tracker.set_learnable_params(self.opts['ft_layers'])\n",
    "            init_optimizer = set_optimizer(self.tracker, self.opts['lr_init'], self.opts['lr_mult'])\n",
    "            self.update_optimizer = set_optimizer(self.tracker, self.opts['lr_update'], self.opts['lr_mult'])\n",
    "\n",
    "            # Draw pos/neg samples\n",
    "            pos_examples = SampleGenerator('gaussian', image.size, self.opts['trans_pos'], self.opts['scale_pos'])(\n",
    "                                self.target_bbox, self.opts['n_pos_init'], self.opts['overlap_pos_init'])\n",
    "\n",
    "            neg_examples = np.concatenate([\n",
    "                            SampleGenerator('uniform', image.size, self.opts['trans_neg_init'], self.opts['scale_neg_init'])(\n",
    "                                self.target_bbox, int(self.opts['n_neg_init'] * 0.5), self.opts['overlap_neg_init']),\n",
    "                            SampleGenerator('whole', image.size)(\n",
    "                                self.target_bbox, int(self.opts['n_neg_init'] * 0.5), self.opts['overlap_neg_init'])])\n",
    "            neg_examples = np.random.permutation(neg_examples)\n",
    "\n",
    "            # Extract pos/neg features\n",
    "            pos_feats = self.forward_samples(image, pos_examples)\n",
    "            neg_feats = self.forward_samples(image, neg_examples)\n",
    "\n",
    "            # Initial training\n",
    "            self.train(init_optimizer, pos_feats, neg_feats, self.opts['maxiter_init'])\n",
    "            del init_optimizer, neg_feats\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # Train bbox regressor\n",
    "            bbreg_examples = SampleGenerator('uniform', image.size, self.opts['trans_bbreg'], self.opts['scale_bbreg'], self.opts['aspect_bbreg'])(\n",
    "                                self.target_bbox, self.opts['n_bbreg'], self.opts['overlap_bbreg'])\n",
    "            bbreg_feats = self.forward_samples(image, bbreg_examples)\n",
    "            self.bbreg = BBRegressor(image.size)\n",
    "            self.bbreg.train(bbreg_feats, bbreg_examples, self.target_bbox)\n",
    "            del bbreg_feats\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # Init sample generators for update\n",
    "            self.sample_generator = SampleGenerator('gaussian', image.size, self.opts['trans'], self.opts['scale'])\n",
    "            self.pos_generator = SampleGenerator('gaussian', image.size, self.opts['trans_pos'], self.opts['scale_pos'])\n",
    "            self.neg_generator = SampleGenerator('uniform', image.size, self.opts['trans_neg'], self.opts['scale_neg'])\n",
    "\n",
    "            # Init pos/neg features for update\n",
    "            neg_examples = self.neg_generator(self.target_bbox, self.opts['n_neg_update'], self.opts['overlap_neg_init'])\n",
    "            neg_feats = self.forward_samples(image, neg_examples)\n",
    "            self.pos_feats_all = [pos_feats]\n",
    "            self.neg_feats_all = [neg_feats]\n",
    "\n",
    "        def track(self, image_file):\n",
    "            self.i +=1\n",
    "            image = Image.open(image_file).convert('RGB')\n",
    "\n",
    "            # Estimate target bbox\n",
    "            samples = self.sample_generator(self.target_bbox, self.opts['n_samples'])\n",
    "            sample_scores = self.forward_samples(image, samples, out_layer='fc6')\n",
    "\n",
    "            top_scores, top_idx = sample_scores[:, 1].topk(5)\n",
    "            top_idx = top_idx.cpu()\n",
    "            target_score = top_scores.mean()\n",
    "            self.target_bbox = samples[top_idx]\n",
    "            if top_idx.shape[0] > 1:\n",
    "                self.target_bbox = self.target_bbox.mean(axis=0)\n",
    "            success = target_score > 0\n",
    "                \n",
    "            # Expand search area at failure\n",
    "            if success:\n",
    "                self.sample_generator.set_trans(self.opts['trans'])\n",
    "            else:\n",
    "                self.sample_generator.expand_trans(self.opts['trans_limit'])\n",
    "\n",
    "            # Bbox regression\n",
    "            if success:\n",
    "                bbreg_samples = samples[top_idx]\n",
    "                if top_idx.shape[0] == 1:\n",
    "                    bbreg_samples = bbreg_samples[None,:]\n",
    "                bbreg_feats = self.forward_samples(image, bbreg_samples)\n",
    "                bbreg_samples = self.bbreg.predict(bbreg_feats, bbreg_samples)\n",
    "                bbreg_bbox = bbreg_samples.mean(axis=0)\n",
    "            else:\n",
    "                bbreg_bbox = self.target_bbox\n",
    "\n",
    "            # Data collect\n",
    "            if success:\n",
    "                pos_examples = self.pos_generator(self.target_bbox, self.opts['n_pos_update'], self.opts['overlap_pos_update'])\n",
    "                pos_feats = self.forward_samples(image, pos_examples)\n",
    "                self.pos_feats_all.append(pos_feats)\n",
    "                if len(self.pos_feats_all) > self.opts['n_frames_long']:\n",
    "                    del self.pos_feats_all[0]\n",
    "\n",
    "                neg_examples = self.neg_generator(self.target_bbox, self.opts['n_neg_update'], self.opts['overlap_neg_update'])\n",
    "                neg_feats = self.forward_samples(image, neg_examples)\n",
    "                self.neg_feats_all.append(neg_feats)\n",
    "                if len(self.neg_feats_all) > self.opts['n_frames_short']:\n",
    "                    del self.neg_feats_all[0]\n",
    "\n",
    "            # Short term update\n",
    "            if not success:\n",
    "                nframes = min(self.opts['n_frames_short'], len(self.pos_feats_all))\n",
    "                pos_data = torch.cat(self.pos_feats_all[-nframes:], 0)\n",
    "                neg_data = torch.cat(self.neg_feats_all, 0)\n",
    "                self.train( self.update_optimizer, pos_data, neg_data, self.opts['maxiter_update'])\n",
    "\n",
    "            # Long term update\n",
    "            elif self.i % self.opts['long_interval'] == 0:\n",
    "                pos_data = torch.cat(self.pos_feats_all, 0)\n",
    "                neg_data = torch.cat(self.neg_feats_all, 0)\n",
    "                self.train( self.update_optimizer, pos_data, neg_data, self.opts['maxiter_update'])\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            return bbreg_bbox\n",
    "    \n",
    "    return pyMDNet()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MIL](https://ieeexplore.ieee.org/document/5206737)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"MIL\"\n",
    "url = \"https://github.com/noTban/py-MDNet/archive/refs/heads/master.zip\"\n",
    "clone_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model.py\n"
     ]
    }
   ],
   "source": [
    "%%file -a model.py\n",
    "\n",
    "def get_MIL_tracker():\n",
    "    import cv2\n",
    "    class MIL(Tracker):\n",
    "        def __init__(self):\n",
    "            super().__init__(\"MIL\")\n",
    "            self.tracker = cv2.TrackerMIL_create()\n",
    "\n",
    "        def initialize(self, image_file, box):\n",
    "            image = cv2.imread(image_file)\n",
    "            self.tracker.init(image, box)\n",
    "\n",
    "        def track(self, image_file):\n",
    "            image = cv2.imread(image_file)\n",
    "            _, bbox = self.tracker.update(image)\n",
    "            return bbox\n",
    "  \n",
    "    return MIL()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOTURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"goturn-files\"\n",
    "url = \"https://github.com/spmallick/goturn-files/archive/refs/heads/master.zip\"\n",
    "clone_repo(model, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marius/epita/ING3/DNN/DNN/models/goturn-files\n",
      "/home/marius/epita/ING3/DNN/DNN\n",
      "Archive:  models/goturn-files/goturn.caffemodel.zip\n",
      "  inflating: goturn.caffemodel       \n"
     ]
    }
   ],
   "source": [
    "%cd models/goturn-files\n",
    "!cat goturn.caffemodel.zip* > goturn.caffemodel.zip\n",
    "%cd ../../\n",
    "!unzip models/goturn-files/goturn.caffemodel.zip\n",
    "!cp models/goturn-files/goturn.prototxt ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model.py\n"
     ]
    }
   ],
   "source": [
    "%%file -a model.py\n",
    "\n",
    "def get_GOTURN_tracker():\n",
    "    import cv2\n",
    "    class GOTURN(Tracker):\n",
    "        def __init__(self):\n",
    "            super().__init__(\"GOTURN\")\n",
    "            self.tracker = cv2.TrackerGOTURN_create()\n",
    "\n",
    "        def initialize(self, image_file, box):\n",
    "            image = cv2.imread(image_file)\n",
    "            self.tracker.init(image, box)\n",
    "\n",
    "        def track(self, image_file):\n",
    "            image = cv2.imread(image_file)\n",
    "            _, bbox = self.tracker.update(image)\n",
    "            return bbox\n",
    "  \n",
    "    return GOTURN()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [AAA](https://github.com/songheony/A3T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"A3T\"\n",
    "url = \"https://github.com/Leiyks/A3T/archive/refs/heads/master.zip\"\n",
    "\n",
    "clone_repo(model, url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tracker is a bagging tracker. It uses the tracks of other trackers to make its own predictions. In our testing, we will try to see if the trackers using all the trackers we are testing is better then them individually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (models_folder / \"A3T\" / \"pysot-toolkit\").exists():\n",
    "    %cd models/A3T\n",
    "\n",
    "    # clone frameworks\n",
    "    !git clone https://github.com/songheony/pytracking.git\n",
    "    !git clone https://github.com/StrangerZhang/pysot-toolkit\n",
    "\n",
    "    # install region\n",
    "    %cd pysot-toolkit/pysot/utils/\n",
    "    !python setup.py build_ext --inplace\n",
    "    %cd ../../../../../\t\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some modification on the path used has to be performed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a model.py\n",
    "\n",
    "def get_AAA_tracker():\n",
    "    import numpy as np\n",
    "    class AAA(Tracker):\n",
    "        def __init__(self):\n",
    "            super().__init__(\"AAA\")\n",
    "            import models.A3T.algorithms.aaa as aaa\n",
    "            self.experts = [\n",
    "                get_SESIAMFC_tracker(),\n",
    "                get_PyECO_tracker(),\n",
    "                get_PyECO_tracker(model_name='PyECO_deep'),\n",
    "                get_MixFormer_tracker(),\n",
    "                get_MIL_tracker(),\n",
    "                get_Staple_tracker(),\n",
    "                get_GOTURN_tracker(),\n",
    "            ]\n",
    "            self.n_experts = len(self.experts) # number of experts\n",
    "            theta, gamma = 0.92, 11  # you can tune hyperparameters by running run_tuning.sh\n",
    "            self.tracker = aaa.AAA(self.n_experts, mode=\"LOG_DIR\", threshold=theta)\n",
    "\n",
    "\n",
    "        def initialize(self, image_path, bbox):\n",
    "            for i in range(self.n_experts):\n",
    "                self.experts[i].initialize(image_path, bbox)\n",
    "            self.tracker.initialize(image_path, bbox)\n",
    "\n",
    "        def track(self, image_path):\n",
    "            experts_result = np.zeros((self.n_experts, 4))\n",
    "            for i in range(self.n_experts):\n",
    "                experts_result[i, :] = self.experts[i].track(image_path)\n",
    "            state, offline, weight = self.tracker.track(image_path, experts_result)\n",
    "            return state\n",
    "  \n",
    "    return AAA()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/Documents/DNN_project/projet\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a model.py\n",
    "\n",
    "def load_models() -> Dict[str, Tracker]:\n",
    "    \"\"\"Load all models\n",
    "    Returns:\n",
    "        Dict[str, Tracker]: Dict of models\n",
    "    \"\"\"\n",
    "    ret: Dict[str, Tracker] = {}\n",
    "    \n",
    "    try:\n",
    "        ret['Staple'] = get_Staple_tracker()\n",
    "    except:\n",
    "        ret['Staple'] = get_Staple_tracker()\n",
    "    ret['SEsiamFC'] = get_SESIAMFC_tracker()\n",
    "    ret['AAA'] = get_AAA_tracker()\n",
    "    ret['PyECO'] = get_PyECO_tracker()\n",
    "    ret['PyECO_deep'] = get_PyECO_tracker(model_name='PyECO_deep')\n",
    "    ret['MixFormer'] = get_MixFormer_tracker()\n",
    "    # ret['pyMDNet'] = get_pyMDNet_tracker()\n",
    "    ret['MIL'] = get_MIL_tracker()\n",
    "    ret['GOTURN'] = get_GOTURN_tracker()\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d9252bccb5f40923e9b4c4ab41ecaa42058158df6f26a83ec92f94020728ac1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
