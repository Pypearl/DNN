{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose the following dataset to evaluate different models on tracking tasks:\n",
    "- [TC-128](https://www3.cs.stonybrook.edu/~hling/data/TColor-128/TColor-128.html#dataset) (Present in the article)\n",
    "- [VOT2021](https://www.votchallenge.net/vot2021/dataset.html) (Recent dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook display samples of datasets and how they are modified to feat the models.\n",
    "\n",
    "To feat the models evaluation. The folder should be in the **data** folder and be structured as follow:\n",
    "\n",
    "- *my*dataset_name\n",
    "    - *img*\n",
    "        - img1.jpg\n",
    "        - img2.jpg\n",
    "        - ...\n",
    "    - *groundtruth.txt*\n",
    "\n",
    "---\n",
    "\n",
    "groundtruth.txt should be structured as follow:\n",
    "\n",
    "```\n",
    "x,y,w,h\n",
    "x,y,w,h\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import urllib.request"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change the location with the following cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset.py\n",
    "\n",
    "path_to_dataset = \"/mnt/d/Documents/DNN_project/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import path_to_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TC-128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 128 videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tc128_and_format(all: bool = False):\n",
    "    with urllib.request.urlopen('https://www3.cs.stonybrook.edu/~hling/data/TColor-128/seqs/') as f:\n",
    "        html = f.read().decode('utf-8')\n",
    "        zip = re.findall(r'href=\"(.*?\\.zip)\"', html)\n",
    "\n",
    "    if not os.path.exists(os.path.join(path_to_dataset, 'mytc128')):\n",
    "        os.makedirs(os.path.join(path_to_dataset, 'mytc128'))\n",
    "\n",
    "    for i in range(len(zip)):\n",
    "        zip_without_ext = zip[i][:-4]\n",
    "        path_zip = os.path.join(path_to_dataset, \"mytc128\", zip[i])\n",
    "        path_no_zip = os.path.join(path_to_dataset, \"mytc128\")\n",
    "        \n",
    "        # Download zip file\n",
    "        urllib.request.urlretrieve('https://www3.cs.stonybrook.edu/~hling/data/TColor-128/seqs/'+zip[i], path_zip)\n",
    "        shutil.unpack_archive(path_zip, path_no_zip)\n",
    "        os.remove(path_zip)\n",
    "\n",
    "        # Remove useless files    \n",
    "        os.remove(os.path.join(path_no_zip, zip_without_ext, zip_without_ext + \"_att.txt\"))\n",
    "        os.remove(os.path.join(path_no_zip, zip_without_ext, zip_without_ext + \"_frames.txt\"))\n",
    "        \n",
    "        # Rename groundtruth file to fit the code\n",
    "        os.rename(os.path.join(path_no_zip, zip_without_ext, zip_without_ext + \"_gt.txt\"), os.path.join(path_no_zip, zip_without_ext, \"groundtruth.txt\"))\n",
    "        \n",
    "        if not all:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_tc128_and_format(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOT 2021"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains semantic labelisation of 60 videos. We will use the semantic labelisation to compute the ground truth bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vot\n",
    "from vot import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic2bbox(path_semantic : str, path_bbox : str):\n",
    "    \"\"\"Convert semantic segmentation to bounding box\"\"\"\n",
    "\n",
    "    with open(path_semantic, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        semantic = list(reader)\n",
    "    \n",
    "    semantic = list(map(lambda x: [x[0][1:]] + x[1:], semantic))\n",
    "    semantic = list(map(lambda x: list(map(lambda y: int(y), x)), semantic))\n",
    "    semantic = list(map(lambda x: x[:4], semantic))\n",
    "\n",
    "    with open(path_bbox, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_vot2021_dataset_and_format(all: bool = False):\n",
    "    path_vot2021, path_myvot2021 = os.path.join(path_to_dataset, \"vot2021\"), os.path.join(path_to_dataset, \"myvot2021\")\n",
    "\n",
    "    # Uncomment the following line to download the VOT2021 dataset\n",
    "    dataset.download_dataset(dataset.vot._VOT_DATASETS[\"vot-st2021\"], os.path.join(path_to_dataset, \"vot2021\"))\n",
    "    \n",
    "    if not os.path.exists(path_myvot2021):\n",
    "        os.mkdir(path_myvot2021)\n",
    "    \n",
    "    videos = os.listdir(path_vot2021)\n",
    "    \n",
    "    for video in videos:\n",
    "        if not os.path.isdir(os.path.join(path_vot2021, video)):\n",
    "            continue\n",
    "        if not os.path.exists(os.path.join(path_myvot2021, video)):\n",
    "            os.mkdir(os.path.join(path_myvot2021, video))\n",
    "        semantic2bbox(os.path.join(path_vot2021, video, \"groundtruth.txt\"), os.path.join(path_myvot2021, video, \"groundtruth.txt\"))\n",
    "        shutil.copytree(os.path.join(path_vot2021, video, \"color\"), os.path.join(path_myvot2021, video, \"img\"))\n",
    "        \n",
    "        if not all:\n",
    "            break\n",
    "\n",
    "    shutil.rmtree(path_vot2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_vot2021_dataset_and_format(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a dataset.py\n",
    "\n",
    "import os\n",
    "\n",
    "def load_dataset(name):\n",
    "    data_folders = os.listdir(path_to_dataset)\n",
    "    available = list(filter(lambda x : \"my\" == x[:2], data_folders))\n",
    "    if not any(name == x for x in available):\n",
    "        Exception(\"Dataset not found\")\n",
    "\n",
    "    ret = {}\n",
    "\n",
    "    for folder in os.listdir(os.path.join(path_to_dataset, name)):\n",
    "\n",
    "        try :        \n",
    "            cur = {}\n",
    "\n",
    "            cur[\"name\"] = folder\n",
    "            cur[\"gt\"] = []\n",
    "            folder_path = os.path.join(path_to_dataset, name, folder)\n",
    "            with open(os.path.join(folder_path, \"groundtruth.txt\")) as f:\n",
    "                for line in f:\n",
    "                    cur[\"gt\"].append([int(float(x)) for x in line.split(\",\")])\n",
    "            \n",
    "            cur[\"image_files\"] = list(map(lambda x : os.path.join(os.path.join(folder_path, \"img\"), x), os.listdir(os.path.join(folder_path, \"img\"))))\n",
    "\n",
    "            if len(cur[\"gt\"]) != len(cur[\"image_files\"]):\n",
    "                print(\"Error while loading dataset\", folder, \"gt and image files have different length\")\n",
    "            else:\n",
    "                ret[folder] = cur\n",
    "\n",
    "        except:\n",
    "            print(\"Error while loading dataset\", folder)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a dataset.py\n",
    "\n",
    "def load_datasets():\n",
    "    ret = {}\n",
    "    for folder in os.listdir(path_to_dataset):\n",
    "        if \"my\" == folder[:2]:\n",
    "            ret[folder] = load_dataset(folder)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while loading dataset David gt and image files have different length\n",
      "Error while loading dataset Football1 gt and image files have different length\n",
      "Error while loading dataset Jogging1 gt and image files have different length\n",
      "Error while loading dataset Jogging2 gt and image files have different length\n",
      "Error while loading dataset Subway gt and image files have different length\n"
     ]
    }
   ],
   "source": [
    "ds = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_dnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96d6dd9d829a4a8dd1edda94add76f4a08841e645b8132fdf668d21ba72dd652"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
