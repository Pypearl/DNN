{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose the following dataset to evaluate different models on tracking tasks:\n",
    "- [TC-128](https://www3.cs.stonybrook.edu/~hling/data/TColor-128/TColor-128.html#dataset) (Present in the article) (4.37 Go)\n",
    "- [VOT2021](https://www.votchallenge.net/vot2021/dataset.html) (Recent dataset) (1.23 Go)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook display samples of datasets and how they are modified to feat the models.\n",
    "\n",
    "To feat the models evaluation. The folder should be in the **data** folder and be structured as follow:\n",
    "\n",
    "- *my*dataset_name\n",
    "    - *img*\n",
    "        - img1.jpg\n",
    "        - img2.jpg\n",
    "        - ...\n",
    "    - *groundtruth.txt*\n",
    "\n",
    "---\n",
    "\n",
    "groundtruth.txt should be structured as follow:\n",
    "\n",
    "```\n",
    "x,y,w,h\n",
    "x,y,w,h\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import urllib.request\n",
    "import vot\n",
    "\n",
    "from dataset import path_to_dataset\n",
    "from pathlib import Path\n",
    "from vot import dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change the location with the following cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset.py\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "path_to_dataset = Path(os.getcwd()) / \"data\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TC-128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 128 videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tc128_and_format(all: bool = False):\n",
    "    data_folder = path_to_dataset / \"mytc128\"\n",
    "    if data_folder.exists():\n",
    "        return\n",
    "    \n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "    with urllib.request.urlopen('https://www3.cs.stonybrook.edu/~hling/data/TColor-128/seqs/') as f:\n",
    "        html = f.read().decode('utf-8')\n",
    "        zip = re.findall(r'href=\"(.*?\\.zip)\"', html)\n",
    "\n",
    "    for i in range(len(zip)):\n",
    "        zip_without_ext = zip[i][:-4]\n",
    "        path_zip = data_folder / zip[i]\n",
    "        path_zip_without_ext = data_folder / zip_without_ext\n",
    "        \n",
    "        # Download zip file\n",
    "        urllib.request.urlretrieve('https://www3.cs.stonybrook.edu/~hling/data/TColor-128/seqs/' + zip[i], path_zip)\n",
    "        shutil.unpack_archive(path_zip, data_folder)\n",
    "        os.remove(path_zip)\n",
    "\n",
    "        # Remove useless files\n",
    "        attribute_file = zip_without_ext + \"_att.txt\"\n",
    "        frame_file = (zip_without_ext if zip_without_ext != \"Jogging2\" else \"jogging2\")  + \"_frames.txt\" # Special case for Jogging2\n",
    "        os.remove(str(path_zip_without_ext / attribute_file))\n",
    "        os.remove(str(path_zip_without_ext / frame_file))\n",
    "        \n",
    "        # Rename groundtruth file to fit the code\n",
    "        groundtruth_file = zip_without_ext + \"_gt.txt\"\n",
    "        os.rename(path_zip_without_ext / groundtruth_file, path_zip_without_ext / \"groundtruth.txt\")\n",
    "        \n",
    "        if not all:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_tc128_and_format(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOT 2021"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains semantic labelisation of 60 videos. We will use the semantic labelisation to compute the ground truth bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic2bbox(path_semantic : str, path_bbox : str):\n",
    "    \"\"\"Convert semantic segmentation to bounding box\"\"\"\n",
    "\n",
    "    with open(path_semantic, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        semantic = list(reader)\n",
    "    \n",
    "    semantic = list(map(lambda x: [x[0][1:]] + x[1:], semantic))\n",
    "    semantic = list(map(lambda x: list(map(lambda y: int(y), x)), semantic))\n",
    "    semantic = list(map(lambda x: x[:4], semantic))\n",
    "\n",
    "    with open(path_bbox, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_vot2021_dataset_and_format(all: bool = False):\n",
    "    path_vot2021 = path_to_dataset / \"vot2021\"\n",
    "    path_myvot2021 = path_to_dataset / \"myvot2021\"\n",
    "    \n",
    "    if path_myvot2021.exists():\n",
    "        return\n",
    "\n",
    "    dataset.download_dataset(dataset.vot._VOT_DATASETS[\"vot-st2021\"], path_vot2021)\n",
    "    os.mkdir(path_myvot2021)\n",
    "    \n",
    "    videos = os.listdir(path_vot2021)\n",
    "    \n",
    "    for video in videos:\n",
    "        if not os.path.isdir(path_vot2021 / video):\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(path_myvot2021 / video):\n",
    "            os.mkdir(path_myvot2021 / video)\n",
    "\n",
    "        semantic2bbox(path_vot2021 / video / \"groundtruth.txt\", path_myvot2021 / video / \"groundtruth.txt\")\n",
    "        shutil.copytree(path_vot2021 / video / \"color\", path_myvot2021 / video / \"img\")\n",
    "        \n",
    "        if not all:\n",
    "            break\n",
    "\n",
    "    shutil.rmtree(path_vot2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_vot2021_dataset_and_format(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a dataset.py\n",
    "\n",
    "def load_dataset(name):\n",
    "    data_folders = os.listdir(path_to_dataset)\n",
    "    available = [folder for folder in data_folders if folder.startswith(\"my\")]\n",
    "\n",
    "    if not any(name == x for x in available):\n",
    "        Exception(\"Dataset not found\")\n",
    "\n",
    "    ret = {}\n",
    "\n",
    "    for folder in os.listdir(path_to_dataset / name):\n",
    "        try:\n",
    "            cur = {}\n",
    "            cur[\"name\"] = folder\n",
    "            cur[\"gt\"] = []\n",
    "\n",
    "            folder_path = path_to_dataset / name / folder\n",
    "\n",
    "            with open(folder_path / \"groundtruth.txt\") as f:\n",
    "                for line in f:\n",
    "                    cur[\"gt\"].append([int(float(x)) for x in line.split(\",\")])\n",
    "\n",
    "            cur[\"image_files\"] = [\n",
    "                folder_path / \"img\" / x for x in os.listdir(folder_path / \"img\")\n",
    "            ]\n",
    "\n",
    "            if len(cur[\"gt\"]) != len(cur[\"image_files\"]):\n",
    "                print(f\"Error while loading dataset {folder} gt and image files have different length\")\n",
    "                return\n",
    "\n",
    "            ret[folder] = cur\n",
    "        except:\n",
    "            print(\"Error while loading dataset\", folder)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a dataset.py\n",
    "\n",
    "def load_datasets():\n",
    "    ret = {}\n",
    "    for folder in os.listdir(path_to_dataset):\n",
    "        if folder.startswith(\"my\"):\n",
    "            ret[folder] = load_dataset(folder)\n",
    "    return ret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "948649c324ca7862321fb27243ea9939e0d68076f558125e86352d86ba9fdaa9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
